name: Automated Backup

on:
  schedule:
    # Run backup daily at 1 AM UTC
    - cron: '0 1 * * *'
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - database-only
        - files-only

jobs:
  backup:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Backup production data
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.PRODUCTION_HOST }}
        username: ${{ secrets.PRODUCTION_USERNAME }}
        key: ${{ secrets.PRODUCTION_SSH_KEY }}
        port: ${{ secrets.PRODUCTION_PORT }}
        script: |
          set -e
          
          BACKUP_DIR="/var/backups/sky-portal"
          APP_PATH="/var/www/sky-portal"
          DATE=$(date +%Y%m%d_%H%M%S)
          BACKUP_TYPE="${{ github.event.inputs.backup_type || 'full' }}"
          
          # Create backup directory
          mkdir -p "$BACKUP_DIR"
          
          echo "Starting $BACKUP_TYPE backup at $(date)"
          
          case "$BACKUP_TYPE" in
            "database-only")
              echo "Creating database backup..."
              mysqldump -u ${{ secrets.DB_USERNAME }} -p${{ secrets.DB_PASSWORD }} \
                ${{ secrets.DB_DATABASE }} > "$BACKUP_DIR/database_backup_$DATE.sql"
              gzip "$BACKUP_DIR/database_backup_$DATE.sql"
              echo "Database backup completed: database_backup_$DATE.sql.gz"
              ;;
              
            "files-only")
              echo "Creating files backup..."
              tar -czf "$BACKUP_DIR/files_backup_$DATE.tar.gz" \
                -C "$APP_PATH" \
                --exclude='vendor' \
                --exclude='node_modules' \
                --exclude='.git' \
                --exclude='storage/logs/*' \
                --exclude='storage/framework/cache/*' \
                --exclude='storage/framework/sessions/*' \
                --exclude='storage/framework/views/*' \
                .
              echo "Files backup completed: files_backup_$DATE.tar.gz"
              ;;
              
            "full"|*)
              echo "Creating database backup..."
              mysqldump -u ${{ secrets.DB_USERNAME }} -p${{ secrets.DB_PASSWORD }} \
                ${{ secrets.DB_DATABASE }} > "$BACKUP_DIR/database_backup_$DATE.sql"
              gzip "$BACKUP_DIR/database_backup_$DATE.sql"
              
              echo "Creating files backup..."
              tar -czf "$BACKUP_DIR/files_backup_$DATE.tar.gz" \
                -C "$APP_PATH" \
                --exclude='vendor' \
                --exclude='node_modules' \
                --exclude='.git' \
                --exclude='storage/logs/*' \
                --exclude='storage/framework/cache/*' \
                --exclude='storage/framework/sessions/*' \
                --exclude='storage/framework/views/*' \
                .
              
              echo "Creating combined backup..."
              tar -czf "$BACKUP_DIR/full_backup_$DATE.tar.gz" \
                -C "$BACKUP_DIR" \
                "database_backup_$DATE.sql.gz" \
                -C "$APP_PATH" \
                --exclude='vendor' \
                --exclude='node_modules' \
                --exclude='.git' \
                --exclude='storage/logs/*' \
                --exclude='storage/framework/cache/*' \
                --exclude='storage/framework/sessions/*' \
                --exclude='storage/framework/views/*' \
                .
              
              echo "Full backup completed: full_backup_$DATE.tar.gz"
              ;;
          esac
          
          # Clean up old backups (keep last 30 days)
          find "$BACKUP_DIR" -name "*backup_*.tar.gz" -mtime +30 -delete
          find "$BACKUP_DIR" -name "*backup_*.sql.gz" -mtime +30 -delete
          
          # Show backup status
          echo "Backup directory contents:"
          ls -lah "$BACKUP_DIR" | tail -10
          
          echo "Backup completed successfully at $(date)"

    - name: Verify backup integrity
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.PRODUCTION_HOST }}
        username: ${{ secrets.PRODUCTION_USERNAME }}
        key: ${{ secrets.PRODUCTION_SSH_KEY }}
        port: ${{ secrets.PRODUCTION_PORT }}
        script: |
          BACKUP_DIR="/var/backups/sky-portal"
          DATE=$(date +%Y%m%d)
          
          # Find today's backup files
          LATEST_BACKUP=$(find "$BACKUP_DIR" -name "*backup_${DATE}*.tar.gz" -o -name "*backup_${DATE}*.sql.gz" | head -1)
          
          if [ -z "$LATEST_BACKUP" ]; then
            echo "ERROR: No backup file found for today"
            exit 1
          fi
          
          # Test backup file integrity
          if file "$LATEST_BACKUP" | grep -q "gzip compressed"; then
            echo "Backup file integrity check passed: $LATEST_BACKUP"
          else
            echo "ERROR: Backup file integrity check failed: $LATEST_BACKUP"
            exit 1
          fi

    - name: Upload to cloud storage (optional)
      uses: appleboy/ssh-action@v1.0.0
      if: secrets.AWS_ACCESS_KEY_ID != ''
      with:
        host: ${{ secrets.PRODUCTION_HOST }}
        username: ${{ secrets.PRODUCTION_USERNAME }}
        key: ${{ secrets.PRODUCTION_SSH_KEY }}
        port: ${{ secrets.PRODUCTION_PORT }}
        script: |
          # Upload to AWS S3 (if configured)
          if command -v aws >/dev/null 2>&1; then
            BACKUP_DIR="/var/backups/sky-portal"
            DATE=$(date +%Y%m%d)
            
            # Configure AWS credentials
            aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws configure set default.region ${{ secrets.AWS_REGION }}
            
            # Upload latest backup to S3
            LATEST_BACKUP=$(find "$BACKUP_DIR" -name "*backup_${DATE}*.tar.gz" | head -1)
            if [ -n "$LATEST_BACKUP" ]; then
              aws s3 cp "$LATEST_BACKUP" s3://${{ secrets.AWS_BACKUP_BUCKET }}/sky-portal/
              echo "Backup uploaded to S3: $LATEST_BACKUP"
            fi
          else
            echo "AWS CLI not installed, skipping cloud upload"
          fi

    - name: Notify backup status
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        text: |
          Backup ${{ job.status }}!
          Type: ${{ github.event.inputs.backup_type || 'scheduled-full' }}
          Time: $(date)
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
